{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Light_fm_model_output.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfNcf2ZhV_vk",
        "outputId": "7e93a3c6-1e25-42ef-ab74-0c6bb3053fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr7-8YA3WF6C",
        "outputId": "f1df503c-fcaa-443a-d1e0-23e9675571e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705386 sha256=2f585fe750eaa3266afcde8adab07c6f14db62fb524189110d91c650e017472d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k,auc_score,reciprocal_rank\n",
        "import scipy\n",
        "import time\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,roc_auc_score\n",
        "from math import sqrt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import recall_score,precision_score\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "import pickle\n",
        "import math"
      ],
      "metadata": {
        "id": "uFEgAlGWWJWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Project/nan_clean_dataset.csv\")\n",
        "final_dataset['date'] =pd.to_datetime(final_dataset.date)\n",
        "final_dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aVy7o2paO5V",
        "outputId": "0e786fef-7722-40a7-e984-24f2d3513fd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'user_id', 'business_id', 'review_id',\n",
              "       'rating', 'date', 'useful_x', 'funny_x', 'cool_x', 'text', 'name_x',\n",
              "       'address', 'city', 'state', 'postal_code', 'latitude', 'longitude',\n",
              "       'stars', 'review_count_x', 'category', 'RestaurantsAttire',\n",
              "       'RestaurantsTakeOut', 'Alcohol', 'RestaurantsDelivery', 'WiFi',\n",
              "       'GoodForKids', 'RestaurantsReservations', 'HasTV', 'Caters',\n",
              "       'RestaurantsPriceRange2', 'BikeParking', 'BusinessAcceptsCreditCards',\n",
              "       'RestaurantsGoodForGroups', 'NoiseLevel', 'OutdoorSeating', 'name_y',\n",
              "       'review_count_y', 'yelping_since', 'useful_y', 'funny_y', 'cool_y',\n",
              "       'elite', 'friends', 'fans', 'average_stars', 'compliment_hot',\n",
              "       'compliment_more', 'compliment_profile', 'compliment_cute',\n",
              "       'compliment_list', 'compliment_note', 'compliment_plain',\n",
              "       'compliment_cool', 'compliment_funny', 'compliment_writer',\n",
              "       'compliment_photos'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample2 = final_dataset.drop(columns=['Unnamed: 0','Unnamed: 0.1','elite','address','state','postal_code','latitude','longitude'])\n"
      ],
      "metadata": {
        "id": "s3Y-fOiCbPpX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_=final_dataset.user_id.value_counts()\n",
        "active_users = users_.loc[users_ >5].index.to_list()\n",
        "active = pd.DataFrame({\"user_id\": active_users})\n",
        "df_sample2 = pd.merge(left = final_dataset,right= active,left_on='user_id',right_on='user_id')"
      ],
      "metadata": {
        "id": "Y6hn21wbbaIq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_sample2.groupby(['user_id']).date.apply(lambda x: max(x)).reset_index()\n",
        "df_test = pd.merge(df_sample2,df, how='inner',on=['user_id','date'])\n",
        "df_train=df_sample2[~df_sample2.isin(df_test.to_dict('l')).all(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIwnnrhgbbxz",
        "outputId": "e983e337-a6cc-4590-a524-f1e0da14ea82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93m_X48Kve8N"
      },
      "source": [
        "# read in cleaned review data\n",
        "review_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/ratings1.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_sn0CWve8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c799905-0281-4b13-9ce8-26290065956e"
      },
      "source": [
        "business_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/business3.csv',index_col=0)\n",
        "user_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/users_tag.csv',index_col=0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = review_df.user_id.unique().shape[0]\n",
        "n_items = review_df.business_id.unique().shape[0]\n",
        "print('Number of users: {}'.format(n_users))\n",
        "print('Number of models: {}'.format(n_items))\n",
        "#print('Sparsity: {:4.3f}%'.format(float(review_df.shape[0]) / float(n_users*n_items) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSzdCGJPWZyZ",
        "outputId": "9e65a560-1ef0-4f50-bf09-aa921747677e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 4001\n",
            "Number of models: 1064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.cool = pd.Series([math.log(x+1) for x in review_df.cool])\n",
        "review_df.useful = pd.Series([math.log(x+1) for x in review_df.useful])\n",
        "review_df.funny = pd.Series([math.log(x+1) for x in review_df.funny])"
      ],
      "metadata": {
        "id": "BkfekvnkWbp5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean user skewness\n",
        "user_df.review_count = pd.Series([math.log(x+1) for x in user_df.review_count])\n",
        "user_df.useful =  pd.Series([math.log(x+1) for x in user_df.useful])\n",
        "\n",
        "#cleam business skewness\n",
        "business_df.review_count =  pd.Series([math.log(x+1) for x in business_df.review_count])"
      ],
      "metadata": {
        "id": "brDKeG1IWdPw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_df=user_df[['average_stars','compliment_cool', 'compliment_cute',\n",
        "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
        "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
        "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool',\n",
        "        'funny', 'review_count', 'useful','is_elite', 'year','user_id']]"
      ],
      "metadata": {
        "id": "bc_otEx8We93"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5w7AiTKm1gk"
      },
      "source": [
        "Building dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnfPSLA2ve8m"
      },
      "source": [
        "#model establishment\n",
        "dataset = Dataset()\n",
        "dataset.fit(review_df.user_id,review_df.business_id)\n",
        "type(dataset)\n",
        "num_users, num_items = dataset.interactions_shape()\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.fit_partial(items=business_df.business_id,\n",
        "                    item_features=['stars'])\n",
        "dataset.fit_partial(items=business_df.business_id,\n",
        "                    item_features=['review_count'])\n",
        "tar_cols = [x for x in business_df.columns[26:]]\n",
        "\n",
        "dataset.fit_partial(items = business_df.business_id,\n",
        "                   item_features = tar_cols)                                    \n",
        "                                                \n",
        "\n",
        "user_cols = [x for x in user_df[['compliment_cool', 'compliment_cute',\n",
        "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
        "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
        "       'compliment_plain', 'compliment_profile', 'compliment_writer', \n",
        "         'review_count', 'useful','is_elite']]]\n",
        "dataset.fit_partial(users=user_df.user_id,\n",
        "                    user_features = user_cols)"
      ],
      "metadata": {
        "id": "ydTm-Qp9SIOG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build interaction\n",
        "(interactions, weights) = dataset.build_interactions([(x['user_id'],\n",
        "                                                       x['business_id'],\n",
        "                                                       x['rating']) for index,x in review_df.iterrows()])\n",
        "\n",
        "print(repr(interactions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1PY7PG1WmIR",
        "outputId": "c2299bc4-4e07-4d29-c7e0-a734fb6c157c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<43234x20016 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 26183 stored elements in COOrdinate format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building item and user matrix\n",
        "def build_dict(df,tar_cols,val_list):\n",
        "    rst = {}\n",
        "    for col in tar_cols:\n",
        "        rst[col] = df[col]\n",
        "    sum_val = sum(list(rst.values())) # get sum of all the tfidf values\n",
        "    \n",
        "    if(sum_val == 0):\n",
        "        return rst\n",
        "    else:\n",
        "        \n",
        "        w = (2-sum(val_list))/sum_val # weight for each tag to be able to sum to 1\n",
        "        for key,value in rst.items():\n",
        "            rst[key] = value * w\n",
        "    return rst\n",
        "\n",
        "def user_build_dict(df,tar_cols,val_list):\n",
        "    rst = {}\n",
        "    for col in tar_cols:\n",
        "        rst[col] = df[col]\n",
        "    sum_val = sum(list(rst.values())) # get sum of all the tfidf values\n",
        "    \n",
        "    if(sum_val == 0):\n",
        "        return rst\n",
        "    else:\n",
        "        w = (2-sum(val_list))/sum_val # weight for each tag to be able to sum to 1\n",
        "        for key,value in rst.items():\n",
        "            rst[key] = value * w\n",
        "    return rst\n",
        "\n",
        "# get max of each column to regularize value to [0,1]\n",
        "max_star = max(business_df.stars)\n",
        "max_b_rc = max(business_df.review_count)\n",
        "print('max_b_rc')\n",
        "print(max_b_rc)\n",
        "\n",
        "# give CF info weight 0.5, all other 0.5. Then in others, give (star, review count) 0.25 and tags 0.25\n",
        "item_features = dataset.build_item_features(((x['business_id'], \n",
        "                                              {'stars':0.5*x['stars']/max_star,\n",
        "                                               'review_count':0.5*x['review_count']/max_b_rc,\n",
        "                                               **build_dict(x,tar_cols,[0.5*x['stars']/max_star,\n",
        "                                                           0.5*x['review_count']/max_b_rc])})\n",
        "                                              for index,x in business_df.iterrows()))\n",
        "\n",
        "\n",
        "# user_features = dataset.build_user_features(((x['user_id'],\n",
        "#                                              [x['is_elite'],x['year']])\n",
        "#                                            for index, x in data_users.iterrows()))\n",
        "max_u_rc = max(user_df.review_count)\n",
        "max_useful = max(user_df.useful)\n",
        "user_features = dataset.build_user_features(((x['user_id'],\n",
        "                                             {'review_count':0.35*x['review_count']/max_u_rc,'is_elite':0.35*int(x['is_elite']),\n",
        "                                              'useful':0.35*x['useful']/max_useful,\n",
        "                                             **user_build_dict(x,user_cols,[0.35*x['review_count']/max_u_rc,\n",
        "                                                                            0.35*int(x['is_elite']),\n",
        "                                                                            0.35*x['useful']/max_useful])})\n",
        "                                           for index, x in user_df.iterrows()))\n",
        "\n",
        "print(repr(item_features))\n",
        "print(item_features.shape)\n",
        "\n",
        "print(repr(user_features))\n",
        "print(user_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl0oING8Wogt",
        "outputId": "1bcd8caf-e6fa-4167-c278-0106a099254c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_b_rc\n",
            "9.12543586488574\n",
            "<20016x20079 sparse matrix of type '<class 'numpy.float32'>'\n",
            "\twith 1281024 stored elements in Compressed Sparse Row format>\n",
            "(20016, 20079)\n",
            "<43234x43248 sparse matrix of type '<class 'numpy.float32'>'\n",
            "\twith 606258 stored elements in Compressed Sparse Row format>\n",
            "(43234, 43248)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "train,test=random_train_test_split(interactions,test_percentage=0.2,random_state=np.random.RandomState(seed))\n",
        "\n",
        "print('The dataset has %s users and %s items, '\n",
        "      'with %s interactions in the test and %s interactions in the training set.'\n",
        "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))\n",
        "\n",
        "train.multiply(test).nnz == 0 # make sure train and test are truly disjoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnYug6TSWq34",
        "outputId": "9446ad08-225d-4db3-d374-9911b88c8fed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 43234 users and 20016 items, with 5237 interactions in the test and 20946 interactions in the training set.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=5\n",
        "NUM_THREADS = 25\n",
        "NUM_COMPONENTS = 42    \n",
        "NUM_EPOCHS = 14\n",
        "ITEM_ALPHA = 0.000256\n",
        "learning_rate=0.0529\n",
        "# WARP\n",
        "model_iii = LightFM(loss='warp',\n",
        "                item_alpha=ITEM_ALPHA, random_state=seed,\n",
        "               no_components=NUM_COMPONENTS)\n",
        "\n",
        "#time it.\n",
        "%time model_iii = model_iii.fit(train,user_features=user_features,item_features=item_features,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
        "\n",
        "\n",
        "\n",
        "# Compute and print the AUC score\n",
        "train_auc = auc_score(model_iii, train,user_features=user_features,item_features=item_features, num_threads=NUM_THREADS).mean()\n",
        "print('Hybrid train AUC: %s' % train_auc)\n",
        "\n",
        "test_auc = auc_score(model_iii, test,user_features=user_features,item_features=item_features,num_threads=NUM_THREADS).mean()\n",
        "print('Hybrid test AUC: %s' % test_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q9ROwMTWsrp",
        "outputId": "0397676d-fd71-49c8-a551-12e756f55b2d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18.7 s, sys: 16.9 ms, total: 18.7 s\n",
            "Wall time: 9.63 s\n",
            "Hybrid train AUC: 0.99283177\n",
            "Hybrid test AUC: 0.9852828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Rec_fx as rf"
      ],
      "metadata": {
        "id": "1TkwtfNZWwpR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.sample_train_recommendation(model_iii,train,business_df,[600],5,'name',mapping=dataset.mapping()[2],tag='category',\n",
        "                              user_features = user_features,item_features=item_features)\n",
        "\n",
        "rf.sample_test_recommendation(model_iii,train,test,business_df,[1],5,'name',mapping=dataset.mapping()[2],\n",
        "                              train_interactions=train,tag='category',user_features = user_features,item_features=item_features)"
      ],
      "metadata": {
        "id": "PSCcayXhW1Sf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60895d7d-b115-442f-ec6f-2a76a744b5a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User 600**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Known positives:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bawarchi Tikka Kabob & Curry House | Indian, Restaurants\n",
            " The Roost | Bars, Restaurants, Sandwiches, American (Traditional), Cocktail Bars, Chicken Shop, Nightlife\n",
            " Churro | Desserts, Ice Cream & Frozen Yogurt, Food, Food Trucks\n",
            " Little Sub Trailer | Restaurants, Sandwiches, Food Stands\n",
            " L & C Bubble Tea House | Restaurants, Coffee & Tea, Taiwanese, Food\n",
            " Pacific Grille | Restaurants, American (Traditional)\n",
            " Café Nordstrom | Cafes, Diners, American (New), Restaurants\n",
            " Sugarloop | Desserts, Cafes, Nightlife, Restaurants, Sporting Goods, Shopping, Food\n",
            " The Meadow | Cards & Stationery, Ethnic Food, Beer, Wine & Spirits, Shopping, Candy Stores, Arts & Crafts, Beauty & Spas, Florists, Cosmetics & Beauty Supply, Chocolatiers & Shops, Food, Specialty Food, Event Planning & Services, Herbs & Spices, Gift Shops, Flowers & Gifts\n",
            " Sciué Italian Bakery Caffé | Breakfast & Brunch, Pizza, Coffee & Tea, Italian, Restaurants, Bakeries, Food, Cafes\n",
            " Starbucks | Food, Coffee & Tea, Bakeries\n",
            " Popeyes Louisiana Kitchen | Cajun/Creole, American (Traditional), Restaurants, Food, Fast Food, Desserts, Chicken Wings\n",
            " Moonlight Grill | Restaurants, Mediterranean\n",
            " Bluehour | French, Greek, Mediterranean, Lounges, Italian, Nightlife, Restaurants, Wine Bars, Bars\n",
            " House of Dosas | Indian, Pakistani, Restaurants, Ethnic Food, Food, Beer, Wine & Spirits, Specialty Food\n",
            " IHOP | Burgers, Restaurants, Breakfast & Brunch, American (New), Diners, American (Traditional)\n",
            " The Garden Strathcona | Food, Flowers & Gifts, Shopping, Bakeries, Cafes, Restaurants\n",
            " J & T Market & Deli | Delis, Grocery, Beer, Wine & Spirits, Food, Restaurants, International Grocery, Convenience Stores\n",
            " Frutas Locas | Specialty Food, Juice Bars & Smoothies, Candy Stores, Food, Desserts, Fruits & Veggies\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Recommended:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Zaika Indian Contemporary Cuisine | Restaurants, Indian\n",
            " Nana's Ice Cream Scoop Shop | Food, Ice Cream & Frozen Yogurt\n",
            " Ocean King Market | Food, Seafood Markets, International Grocery, Specialty Food, Ethnic Food\n",
            " Plumper Pumpkin Patch and Tree Farm | Home Services, Farms, Specialty Food, Local Flavor, Food, Plumbing, Fruits & Veggies, Arts & Entertainment, Attraction Farms, Home Decor, Pumpkin Patches, Home & Garden, Christmas Trees, Farmers Market, Shopping\n",
            " Yaletown Liquor Store | Beer, Wine & Spirits, Food\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*k_p: 19*"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*precicion at k : 0.0*"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User 1**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of known_positives: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Known positives:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Urban Pantry | Do-It-Yourself Food, Restaurants, American (Traditional), Active Life, Grocery, Food, Local Flavor, Specialty Food, Kids Activities, Cafes, Delis\n",
            " Ocean King Market | Food, Seafood Markets, International Grocery, Specialty Food, Ethnic Food\n",
            " Brian's Brew | Food, Coffee & Tea\n",
            " Take Five Café | Food, Coffee & Tea, Restaurants, Cafes\n",
            " Zaika Indian Contemporary Cuisine | Restaurants, Indian\n",
            " HOTLIPS Pizza - Hawthorne | Food, Beer, Wine & Spirits, Restaurants, Fast Food, Pizza, Gluten-Free\n",
            " Greater Goods Coffee Roasters | Coffee Roasteries, Cafes, Food, Coffee & Tea, Restaurants\n",
            " A Thai Basil | Food Stands, Food, Thai, Food Trucks, Bubble Tea, Restaurants\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Recommended:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Let's Roll Custom Sushi Bar | Restaurants, Canadian (New), Sushi Bars, American (New)\n",
            " Nana's Ice Cream Scoop Shop | Food, Ice Cream & Frozen Yogurt\n",
            " Brian's Brew | Food, Coffee & Tea\n",
            "This one clicked\n",
            " Taqueria So Mexican | Restaurants, Mexican, Food Trucks, Food, Food Stands\n",
            " Jackson's Poultry | Food, Specialty Food, Farmers Market, Butcher, Meat Shops\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*k_p: 8*"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*precicion at k : 0.2*"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}